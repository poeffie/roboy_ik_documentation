{
    "docs": [
        {
            "location": "/", 
            "text": "Roboy 2.0 - Inverse Kinematics\n\n\nFor an advanced interaction of Roboy with the environment it is useful to move parts of the body to desired positions. Such body parts could be arms, legs, shoulder, head, etc. This would open up lots of new possibilities, like grabbing small objects with Roboy's hands, moving the legs (PaBiLegs) to desired positions or looking around.\n\n\nGoal\n\n\nRoboy 2.0 should therefore have the possibility to be controlled in a way, that desired positions in space can be reached. This kind of control is called inverse kinematics (IK).\nInverse kinematics in general means calculating joint angles of the robot for a given position in space.\nThe opposite of IK is called forward kinematics, which describes computing the position in space by knowing about the values of the joint parameters.\n\n\n\n\nDifficulties\n\n\nIn contrast to forward kinematics, calculating the inverse kinematics is a difficult task. For a desired position in space there could be infinitely many solutions. As an example, we can think about pressing our hand on a flat table, but still having the possibility to move the ellbow in an angle range. The difficulty is therefore to find an appropriate solution. A further difficculty is, that some of the found solutions may be mathematically correct, but physically not executable. In general there are three ways to solve the IK, numerical, geometrical and algebraical methods. In order not to have to calculate these by hand, there are several tools and solvers freely usable, which we will discuss later. \n\n\nBut apart from the so far called challenges, Roboy comes with an even increased complexity. Roboy is tendon driven. Instead of direct joint angles, the state of a body part is described by the lengths of the tendons. We therefore need to consider a calulation from joint angles to tendon lengths. This aspect led us overthink the conventional way of computing IK and search for an more appropriate solution.\n\n\nApproach\n\n\nIn the case of Roboy, the space is three dimensional (x, y, z) and the joint angles describe the motor states of Roboy's body parts. Considering the PaBiLegs the space is just two dimensional, which simplifies the task of calulating the joint angles and could theoretically be calculated manually by hand. But for a general solution for all kinds of body parts we are going to take a 3D IK solver in consideration.\n\n\nTo make inverse kinematics possible, the approach is to do calculate the joint angles of the inverse kinematics with a solver software. For this we are using a common robot motion planning tool, called ROS MoveIt! The additional challenge due to the tendons can be tackled with a software tool called CASPR. In summary, CASPR allows us to simulate and output tendon lengths by a given joint trajectory. Combining these tools and making them accessable via ROS service is our approach for the Roboy 2.0 IK problem. Both tools will be described in detail in the following chapters.\nThe figure belows depicts the system architecture. We will explain the difference between CASPR and CASPROS more preisely later in the next chapter.\n\n\n\n\nSources\n\n\nA. D'Souza, S. Vijayakumar and S. Schaal, \n\"Learning inverse kinematics,\"\n Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180), Maui, HI, 2001, pp. 298-303 vol.1.\ndoi: 10.1109/IROS.2001.973374\n\n\nhttp://wiki.roblox.com/index.php?title=Inverse_kinematics\n\n\nhttp://www.diag.uniroma1.it/~deluca/rob1_en/10_InverseKinematics.pdf\n\n\nhttps://appliedgo.net/roboticarm/", 
            "title": "Inverse Kinematics"
        }, 
        {
            "location": "/#roboy-20-inverse-kinematics", 
            "text": "For an advanced interaction of Roboy with the environment it is useful to move parts of the body to desired positions. Such body parts could be arms, legs, shoulder, head, etc. This would open up lots of new possibilities, like grabbing small objects with Roboy's hands, moving the legs (PaBiLegs) to desired positions or looking around.", 
            "title": "Roboy 2.0 - Inverse Kinematics"
        }, 
        {
            "location": "/#goal", 
            "text": "Roboy 2.0 should therefore have the possibility to be controlled in a way, that desired positions in space can be reached. This kind of control is called inverse kinematics (IK).\nInverse kinematics in general means calculating joint angles of the robot for a given position in space.\nThe opposite of IK is called forward kinematics, which describes computing the position in space by knowing about the values of the joint parameters.", 
            "title": "Goal"
        }, 
        {
            "location": "/#difficulties", 
            "text": "In contrast to forward kinematics, calculating the inverse kinematics is a difficult task. For a desired position in space there could be infinitely many solutions. As an example, we can think about pressing our hand on a flat table, but still having the possibility to move the ellbow in an angle range. The difficulty is therefore to find an appropriate solution. A further difficculty is, that some of the found solutions may be mathematically correct, but physically not executable. In general there are three ways to solve the IK, numerical, geometrical and algebraical methods. In order not to have to calculate these by hand, there are several tools and solvers freely usable, which we will discuss later.   But apart from the so far called challenges, Roboy comes with an even increased complexity. Roboy is tendon driven. Instead of direct joint angles, the state of a body part is described by the lengths of the tendons. We therefore need to consider a calulation from joint angles to tendon lengths. This aspect led us overthink the conventional way of computing IK and search for an more appropriate solution.", 
            "title": "Difficulties"
        }, 
        {
            "location": "/#approach", 
            "text": "In the case of Roboy, the space is three dimensional (x, y, z) and the joint angles describe the motor states of Roboy's body parts. Considering the PaBiLegs the space is just two dimensional, which simplifies the task of calulating the joint angles and could theoretically be calculated manually by hand. But for a general solution for all kinds of body parts we are going to take a 3D IK solver in consideration.  To make inverse kinematics possible, the approach is to do calculate the joint angles of the inverse kinematics with a solver software. For this we are using a common robot motion planning tool, called ROS MoveIt! The additional challenge due to the tendons can be tackled with a software tool called CASPR. In summary, CASPR allows us to simulate and output tendon lengths by a given joint trajectory. Combining these tools and making them accessable via ROS service is our approach for the Roboy 2.0 IK problem. Both tools will be described in detail in the following chapters.\nThe figure belows depicts the system architecture. We will explain the difference between CASPR and CASPROS more preisely later in the next chapter.", 
            "title": "Approach"
        }, 
        {
            "location": "/#sources", 
            "text": "A. D'Souza, S. Vijayakumar and S. Schaal,  \"Learning inverse kinematics,\"  Proceedings 2001 IEEE/RSJ International Conference on Intelligent Robots and Systems. Expanding the Societal Role of Robotics in the the Next Millennium (Cat. No.01CH37180), Maui, HI, 2001, pp. 298-303 vol.1.\ndoi: 10.1109/IROS.2001.973374  http://wiki.roblox.com/index.php?title=Inverse_kinematics  http://www.diag.uniroma1.it/~deluca/rob1_en/10_InverseKinematics.pdf  https://appliedgo.net/roboticarm/", 
            "title": "Sources"
        }, 
        {
            "location": "/caspr_os/", 
            "text": "What is CASPR?\n\n\nCASPR is a opensource simulation tool, written in MatLab. It is developed for researching purposes in the area of tendon driven robots, so called CDPRs (Cable-driven parallel robots). Basically the simulation software is able to perform analysis in the following fields of study:\n\n\n\n\nDynamics and Control\n\n\nForward Dynamics\n\n\nInverse Dynamics\n\n\nMotion Control\n\n\nKinematics (Forward Kinematics, Inverse Kinematics)\n\n\nWorkspace Analysis\n\n\nDesign Optimisation\n\n\n\n\nCASPR provides a GUI, which allows easy and intuitive access to the to main functions.\nIn general one starts by chosing a robotic model. These models are simplifications of the actual robots one is interested in. Robot models in CASPR are basically build with three different primitives\n\n\n\n\nLinks\n\n\nJoints\n\n\nCables\n\n\n\n\nwhere links and cables are straight lines with predefined start and end positions in space and joints provide the connection between the links. The image below depicts the CASPR GUI, where you can see a primitive robot model, a simple arm with just one joint. It is visualized in the 3D coordinate system. The black lines are the links, black circles the joints, blue circles center of masses and the red lines are the cables / tendons. The model position at the bottom of the picture shows the initial joint angle.\n\n\n\n\nCASPR models are always build of three .xml files. One file for the body description (links, joints, center of masses), one for the cables (attachment points) and another file describing a joint trajectory. How we build our own model will be described later.\n\n\nIs a robot model chosen, one can start the simulation. In our case this is inverse kinematics, that can be reached by clicking on \n\"Kinematics\"\n button, chose \"Inverse Kinematics\" in the \n\"Solver Information\"\n field and finally press the \n\"Run\"\n button. What CASPR now basically does is, that it sets the joint angles accordingly to the joint trajectory, that is described in the xml file. This makes the robot move its links and increase / decrease the cables, as these have a fixed starting point in space and a fixation on arbitrary locations of the robot's links. This means cables are stretching or tightening. The change in length is exactly what we need for our inverse kinematics, as we can use cable lengths to calculate motor commands.\n\n\nAfter a successfull simulation the CASPR GUI offers a varity of output calculations. You can plot a video, visualize the robot's movement or / and plot several outputs, like cable lengths, velocity, acceleration, etc. It is also possible to execute these calculations without the GUI by running a script. I will explain this in the PaBiLegs example below. The figure below shows for instance how such an cable length output could look like. in this case the link moved along the y axis to 90\u00b0, followed by -90\u00b0 and finally back to the initial position of 0\u00b0.\n\n\n\n\nWhat is CASPROS?\n\n\nThe difference between CASPR and CASPROS is basically that CASPROS works completely on C++ and is accessible by. it also does not provide a GUI and outputs not cable lengths, but motor commands to control real robots. So CASPROS is the linkage we need to control Roboy, while CASPR offers us a tool for simulation and research purposes, e.g. validating our robot models.\n\n\nSources:\n\n\nOfficial CASPR repository\n\n\nResearch - Control - What Kind Of Code is CASPR", 
            "title": "Basics"
        }, 
        {
            "location": "/caspr_os/#what-is-caspr", 
            "text": "CASPR is a opensource simulation tool, written in MatLab. It is developed for researching purposes in the area of tendon driven robots, so called CDPRs (Cable-driven parallel robots). Basically the simulation software is able to perform analysis in the following fields of study:   Dynamics and Control  Forward Dynamics  Inverse Dynamics  Motion Control  Kinematics (Forward Kinematics, Inverse Kinematics)  Workspace Analysis  Design Optimisation   CASPR provides a GUI, which allows easy and intuitive access to the to main functions.\nIn general one starts by chosing a robotic model. These models are simplifications of the actual robots one is interested in. Robot models in CASPR are basically build with three different primitives   Links  Joints  Cables   where links and cables are straight lines with predefined start and end positions in space and joints provide the connection between the links. The image below depicts the CASPR GUI, where you can see a primitive robot model, a simple arm with just one joint. It is visualized in the 3D coordinate system. The black lines are the links, black circles the joints, blue circles center of masses and the red lines are the cables / tendons. The model position at the bottom of the picture shows the initial joint angle.   CASPR models are always build of three .xml files. One file for the body description (links, joints, center of masses), one for the cables (attachment points) and another file describing a joint trajectory. How we build our own model will be described later.  Is a robot model chosen, one can start the simulation. In our case this is inverse kinematics, that can be reached by clicking on  \"Kinematics\"  button, chose \"Inverse Kinematics\" in the  \"Solver Information\"  field and finally press the  \"Run\"  button. What CASPR now basically does is, that it sets the joint angles accordingly to the joint trajectory, that is described in the xml file. This makes the robot move its links and increase / decrease the cables, as these have a fixed starting point in space and a fixation on arbitrary locations of the robot's links. This means cables are stretching or tightening. The change in length is exactly what we need for our inverse kinematics, as we can use cable lengths to calculate motor commands.  After a successfull simulation the CASPR GUI offers a varity of output calculations. You can plot a video, visualize the robot's movement or / and plot several outputs, like cable lengths, velocity, acceleration, etc. It is also possible to execute these calculations without the GUI by running a script. I will explain this in the PaBiLegs example below. The figure below shows for instance how such an cable length output could look like. in this case the link moved along the y axis to 90\u00b0, followed by -90\u00b0 and finally back to the initial position of 0\u00b0.", 
            "title": "What is CASPR?"
        }, 
        {
            "location": "/caspr_os/#what-is-caspros", 
            "text": "The difference between CASPR and CASPROS is basically that CASPROS works completely on C++ and is accessible by. it also does not provide a GUI and outputs not cable lengths, but motor commands to control real robots. So CASPROS is the linkage we need to control Roboy, while CASPR offers us a tool for simulation and research purposes, e.g. validating our robot models.  Sources:  Official CASPR repository  Research - Control - What Kind Of Code is CASPR", 
            "title": "What is CASPROS?"
        }, 
        {
            "location": "/caspr_inst/", 
            "text": "CASPR Initialisation\n\n\nCASPR can simply be downloaded \nhere\n and unzipped. As CASPR runs with Matlab only, you also need to have a working version of MatLab.\nTo run CASPR open your MatLab and simply navigate within your \n\"Current Folder\"\n menu into your CASPR folder to execute the \ninitialize_CASPR.m\n file. Is this done sucessfully, navigate (within MatLab) into the GUI folder and execute \nCASPR_GUI.m\n. This should usually work without any errors. \n\n\nIf there occur any errors, it could possibly be due to some dependecies errors. CASPR depends on the following libraries:\n\n\n\n\n'qhull' - a convex hull library that is used throughout the Workspace analysis module. \n\n\n'optitoolbox' - a MATLAB optimisation toolbox. The toolbox is used within the Inverse Dynamics and Design Optimisation modules.\n\n\n\n\nIf any other errors occur, consider reading the full \nCASPR documentation in the \"docs\" folder\n or contacting Darvin Lau.\n\n\nCASPROS Installation\n\n\nFor the \ninstallation\n and \nusage of CASPROS\n I would like to reference to the tutorials, made by a team colleague, Hollie Barnett.", 
            "title": "Installation"
        }, 
        {
            "location": "/caspr_inst/#caspr-initialisation", 
            "text": "CASPR can simply be downloaded  here  and unzipped. As CASPR runs with Matlab only, you also need to have a working version of MatLab.\nTo run CASPR open your MatLab and simply navigate within your  \"Current Folder\"  menu into your CASPR folder to execute the  initialize_CASPR.m  file. Is this done sucessfully, navigate (within MatLab) into the GUI folder and execute  CASPR_GUI.m . This should usually work without any errors.   If there occur any errors, it could possibly be due to some dependecies errors. CASPR depends on the following libraries:   'qhull' - a convex hull library that is used throughout the Workspace analysis module.   'optitoolbox' - a MATLAB optimisation toolbox. The toolbox is used within the Inverse Dynamics and Design Optimisation modules.   If any other errors occur, consider reading the full  CASPR documentation in the \"docs\" folder  or contacting Darvin Lau.", 
            "title": "CASPR Initialisation"
        }, 
        {
            "location": "/caspr_inst/#caspros-installation", 
            "text": "For the  installation  and  usage of CASPROS  I would like to reference to the tutorials, made by a team colleague, Hollie Barnett.", 
            "title": "CASPROS Installation"
        }, 
        {
            "location": "/caspr_model/", 
            "text": "Model Creation - Tutorial\n\n\nIn the following, I am going to describe how to create a CASPR model manually, without using the GUI. This is helpful to understand the principles of CASPR models and for CASPROS model creation, as CASPROS uses the same files like CASPR.\n\n\n1.) In your CASPR-master folder go to /data/model_config\n\n\n2.) Create a new Folder,  e.g. \"myModel\"\n\n\n3.) Create three .xml files, where \"myModel\" can be replaced by the model name, that you wish. \n\n\n\n\nmyModel_bodies.xml\n\n\nmyModel_cables.xml\n\n\nmyModel_trajectories.xml\n\n\n\n\nBody\n\n\n4.) Edit myModel_bodies.xml first. The most Basic Model looks like this:\n\n\n?xml version=\n1.0\n encoding=\nutf-8\n?\n\n\nlinks display_range=\n-1.0 1.0 -1.0 1.0 -1.0 1.0\n view_angle=\n-37 32\n\n  \nlink_rigid num=\n1\n name=\nUpper Arm\n\n    \njoint type=\nS_EULER_XYZ\n q_initial=\n0 0 0\n/\n\n    \nphysical\n\n      \nmass\n1.0\n/mass\n\n      \ncom_location\n0.0 0.25 0.0\n/com_location\n\n      \nend_location\n0.0 0.5 0.0\n/end_location\n\n      \ninertia ref=\ncom\n\n         \nIxx\n0.1\n/Ixx\n\n         \nIyy\n0.1\n/Iyy\n\n         \nIzz\n0.1\n/Izz\n\n         \nIxy\n0.1\n/Ixy\n\n         \nIxz\n0.1\n/Ixz\n\n         \nIyz\n0.1\n/Iyz\n\n      \n/inertia\n\n    \n/physical\n\n    \nparent\n\n      \nnum\n0\n/num\n\n      \nlocation\n0.0 0.0 0.0\n/location\n\n    \n/parent\n\n  \n/link_rigid\n\n\n/links\n\n\n\n\n\nThe name of the body can be set by the attribute \nname=\"NAME\"\n in the \nlink_rigid\n/link_rigid\n element.\nIn general, this code will create a link with its starting postion in \nlocation\n/loaction\n element, here also the coordinate origin.\n\ncom_location\n/com_loaction\n describes the center of mass location in x-y-z coordinates.\n\nend_location\n/end_location\n describes the end location of the link.\n\njoint_type\n/joint_type\n describes the rotation axis of the body.\n\n\nNOTE:\n In this basic example, as well as the following ones, the mass, inertia mass as well as locations are set to arbitrary values. for example here it is mass 1.0 and 0.1 for each inertia mass element. \nFurthermore, the link always rotates around the point of its starting position. These are the possible rotational settings:\n\n\nR_X % Revolute in X\nR_Y % Revolute in Y\nR_Z % Revolute in Z\nU_XY % Universal with xy-euler\nU_YZ % Universal with yz-euler %%\nP_XY % Translational joint in XY plane\nPLANAR_XY % Planar in XY plane\nPLANAR_YZ % Planar in YZ plane\nPLANAR_XZ % Planar in XZ plane %%\nS_EULER_XYZ % Spherical xyz-euler\nS_FIXED_XYZ % Spherical xyz-fixed\nS_QUATERNION % Spherical joint using quaternion\nT_XYZ % Translational joint XYZ\nSPATIAL_QUATERNION % T_XYZ + SPHERICAL\nSPATIAL_EULER_XYZ % T_XYZ + S_EULER_XYZ\n\n\n\n\nInerta matrix and mass will be set depending on the measurements of the robot link, that should be simulated.\nlast but not least is the link number, which is important for attaching cables.\nIt is written in the \nnum\n/num\n element.\n\n\nTrajectory\n\n\n6.) Edit the myModel_trajectorys.xml. The basic trajectory with two joint waypoints could look like this:\n\n\n?xml version=\n1.0\n encoding=\nutf-8\n?\n\n\n!DOCTYPE trajectories [\n\n!ATTLIST linear_spline_trajectory id ID #REQUIRED\n\n\n!ATTLIST cubic_spline_trajectory id ID #REQUIRED\n\n\n!ATTLIST quintic_spline_trajectory id ID #REQUIRED\n\n]\n\n\ntrajectories\n\n  \nquintic_spline_trajectory id=\ntraj_test\n time_definition=\nabsolute\n time_step=\n0.00667\n\n    \npoints\n\n      \npoint\n\n        \nq\n0.0\n/q\n\n        \nq_dot\n0.0\n/q_dot\n\n        \nq_ddot\n0.0\n/q_ddot\n\n      \n/point\n\n      \npoint time=\n1\n\n        \nq\n0.3\n/q\n\n        \nq_dot\n0.0\n/q_dot\n\n        \nq_ddot\n0.0\n/q_ddot\n\n      \n/point\n\n    \n/points\n\n  \n/quintic_spline_trajectory\n\n\n/trajectories\n\n\n\n\n\nIn this case the robot has one planar joint, that moves from 0 degree to 0.3 rad after one second. If the robot has more degrees of freedom, due to more or more complex joints, like spherical ones, one will have to add more q values.\nThe q values are always just seperated by a blank space.\nThe name of the trajectory can be set by the element attribute \nid=\"NAME\"\n.\nExample:\n\n\nq\n0.0 0.0 0.0\n/q\n\n\nq_dot\n0.0 0.0 0.0\n/q_dot\n\n\nq_ddot\n0.0 0.0 0.0\n/q_ddot\n\n\n\n\n\nCables\n\n\n7.) Edit the myModel_cables.xml. For one cable, this file could look like the following:\n\n\n?xml version=\n1.0\n encoding=\nutf-8\n?\n\n\n!DOCTYPE cables [\n\n!ATTLIST cable_set id ID #REQUIRED\n\n]\n\n\ncables default_cable_set=\nCS1\n\n  \ncable_set id=\nCS1\n\n    \ncable_ideal name=\ncable 1\n attachment_reference=\ncom\n\n      \nproperties\n\n        \nforce_min\n5\n/force_min\n\n        \nforce_max\n35\n/force_max\n\n      \n/properties\n\n      \nattachments\n\n        \nattachment\n\n          \nlink\n0\n/link\n\n          \nlocation\n-0.106066 0.020 -0.106066\n/location\n\n        \n/attachment\n\n        \nattachment\n\n          \nlink\n1\n/link\n\n          \nlocation\n-0.025 0.1180 0.0\n/location\n\n        \n/attachment\n\n      \n/attachments\n\n    \n/cable_ideal\n\n  \n/cable_set\n\n\n/cables\n\n\n\n\n\nIn general, the interesting part of a cable are the attachement points. One attaches a cable between two links. The links are described by their \nnum\n/num\n value in the .xml file for the body.\nThe name of the cable set in this case is \"CS1\".\n\n\nIntegrating the model\n\n\nAfter creating the .xml files, one has to link the new model to CASPR.\nThis is done by editing \"models_list.csv\" in directory \n/data/model_config\n.\nOne simple adds another line. In our case, the line could be like this:\n\nMy Model,/MyModel/,myModel_bodies.xml,myModel_cables.xml,myModel_trajectories.xml,\n\n\nNOTE: The line is internally seperated by commas. The first element of the line is the name of our model, this is also the name, that will be displayed in CASPR. The second element is the path to the model files, followed by three elements, the .xml files for body, cables and trajectory.\nAfter saving all files, you are done and successfully created and integrated a new CASPR model!\n\n\nPaBiLegs Example\n\n\nAs an example for a robot model I want to reference here my \nPaBiLegs model\n. The model can be used by creating a new folder in the \nCASPR-master/data/model_config/models/\n location, called \nPaBiLegs\n. After copying the three necessary .xml files, edit \nmodels_list.csv\n by adding this line:\n\nPaBiLegs,/PaBiLegs/,PaBiLegs_bodies.xml,PaBiLegs_cables.xml,PaBiLegs_trajectories.xml,", 
            "title": "Model Creation"
        }, 
        {
            "location": "/caspr_model/#model-creation-tutorial", 
            "text": "In the following, I am going to describe how to create a CASPR model manually, without using the GUI. This is helpful to understand the principles of CASPR models and for CASPROS model creation, as CASPROS uses the same files like CASPR.  1.) In your CASPR-master folder go to /data/model_config  2.) Create a new Folder,  e.g. \"myModel\"  3.) Create three .xml files, where \"myModel\" can be replaced by the model name, that you wish.    myModel_bodies.xml  myModel_cables.xml  myModel_trajectories.xml", 
            "title": "Model Creation - Tutorial"
        }, 
        {
            "location": "/caspr_model/#body", 
            "text": "4.) Edit myModel_bodies.xml first. The most Basic Model looks like this:  ?xml version= 1.0  encoding= utf-8 ?  links display_range= -1.0 1.0 -1.0 1.0 -1.0 1.0  view_angle= -37 32 \n   link_rigid num= 1  name= Upper Arm \n     joint type= S_EULER_XYZ  q_initial= 0 0 0 / \n     physical \n       mass 1.0 /mass \n       com_location 0.0 0.25 0.0 /com_location \n       end_location 0.0 0.5 0.0 /end_location \n       inertia ref= com \n          Ixx 0.1 /Ixx \n          Iyy 0.1 /Iyy \n          Izz 0.1 /Izz \n          Ixy 0.1 /Ixy \n          Ixz 0.1 /Ixz \n          Iyz 0.1 /Iyz \n       /inertia \n     /physical \n     parent \n       num 0 /num \n       location 0.0 0.0 0.0 /location \n     /parent \n   /link_rigid  /links   The name of the body can be set by the attribute  name=\"NAME\"  in the  link_rigid /link_rigid  element.\nIn general, this code will create a link with its starting postion in  location /loaction  element, here also the coordinate origin. com_location /com_loaction  describes the center of mass location in x-y-z coordinates. end_location /end_location  describes the end location of the link. joint_type /joint_type  describes the rotation axis of the body.  NOTE:  In this basic example, as well as the following ones, the mass, inertia mass as well as locations are set to arbitrary values. for example here it is mass 1.0 and 0.1 for each inertia mass element. \nFurthermore, the link always rotates around the point of its starting position. These are the possible rotational settings:  R_X % Revolute in X\nR_Y % Revolute in Y\nR_Z % Revolute in Z\nU_XY % Universal with xy-euler\nU_YZ % Universal with yz-euler %%\nP_XY % Translational joint in XY plane\nPLANAR_XY % Planar in XY plane\nPLANAR_YZ % Planar in YZ plane\nPLANAR_XZ % Planar in XZ plane %%\nS_EULER_XYZ % Spherical xyz-euler\nS_FIXED_XYZ % Spherical xyz-fixed\nS_QUATERNION % Spherical joint using quaternion\nT_XYZ % Translational joint XYZ\nSPATIAL_QUATERNION % T_XYZ + SPHERICAL\nSPATIAL_EULER_XYZ % T_XYZ + S_EULER_XYZ  Inerta matrix and mass will be set depending on the measurements of the robot link, that should be simulated.\nlast but not least is the link number, which is important for attaching cables.\nIt is written in the  num /num  element.", 
            "title": "Body"
        }, 
        {
            "location": "/caspr_model/#trajectory", 
            "text": "6.) Edit the myModel_trajectorys.xml. The basic trajectory with two joint waypoints could look like this:  ?xml version= 1.0  encoding= utf-8 ?  !DOCTYPE trajectories [ !ATTLIST linear_spline_trajectory id ID #REQUIRED  !ATTLIST cubic_spline_trajectory id ID #REQUIRED  !ATTLIST quintic_spline_trajectory id ID #REQUIRED \n]  trajectories \n   quintic_spline_trajectory id= traj_test  time_definition= absolute  time_step= 0.00667 \n     points \n       point \n         q 0.0 /q \n         q_dot 0.0 /q_dot \n         q_ddot 0.0 /q_ddot \n       /point \n       point time= 1 \n         q 0.3 /q \n         q_dot 0.0 /q_dot \n         q_ddot 0.0 /q_ddot \n       /point \n     /points \n   /quintic_spline_trajectory  /trajectories   In this case the robot has one planar joint, that moves from 0 degree to 0.3 rad after one second. If the robot has more degrees of freedom, due to more or more complex joints, like spherical ones, one will have to add more q values.\nThe q values are always just seperated by a blank space.\nThe name of the trajectory can be set by the element attribute  id=\"NAME\" .\nExample:  q 0.0 0.0 0.0 /q  q_dot 0.0 0.0 0.0 /q_dot  q_ddot 0.0 0.0 0.0 /q_ddot", 
            "title": "Trajectory"
        }, 
        {
            "location": "/caspr_model/#cables", 
            "text": "7.) Edit the myModel_cables.xml. For one cable, this file could look like the following:  ?xml version= 1.0  encoding= utf-8 ?  !DOCTYPE cables [ !ATTLIST cable_set id ID #REQUIRED \n]  cables default_cable_set= CS1 \n   cable_set id= CS1 \n     cable_ideal name= cable 1  attachment_reference= com \n       properties \n         force_min 5 /force_min \n         force_max 35 /force_max \n       /properties \n       attachments \n         attachment \n           link 0 /link \n           location -0.106066 0.020 -0.106066 /location \n         /attachment \n         attachment \n           link 1 /link \n           location -0.025 0.1180 0.0 /location \n         /attachment \n       /attachments \n     /cable_ideal \n   /cable_set  /cables   In general, the interesting part of a cable are the attachement points. One attaches a cable between two links. The links are described by their  num /num  value in the .xml file for the body.\nThe name of the cable set in this case is \"CS1\".", 
            "title": "Cables"
        }, 
        {
            "location": "/caspr_model/#integrating-the-model", 
            "text": "After creating the .xml files, one has to link the new model to CASPR.\nThis is done by editing \"models_list.csv\" in directory  /data/model_config .\nOne simple adds another line. In our case, the line could be like this: My Model,/MyModel/,myModel_bodies.xml,myModel_cables.xml,myModel_trajectories.xml,  NOTE: The line is internally seperated by commas. The first element of the line is the name of our model, this is also the name, that will be displayed in CASPR. The second element is the path to the model files, followed by three elements, the .xml files for body, cables and trajectory.\nAfter saving all files, you are done and successfully created and integrated a new CASPR model!", 
            "title": "Integrating the model"
        }, 
        {
            "location": "/caspr_model/#pabilegs-example", 
            "text": "As an example for a robot model I want to reference here my  PaBiLegs model . The model can be used by creating a new folder in the  CASPR-master/data/model_config/models/  location, called  PaBiLegs . After copying the three necessary .xml files, edit  models_list.csv  by adding this line: PaBiLegs,/PaBiLegs/,PaBiLegs_bodies.xml,PaBiLegs_cables.xml,PaBiLegs_trajectories.xml,", 
            "title": "PaBiLegs Example"
        }, 
        {
            "location": "/ros_moveit/", 
            "text": "Basics\n\n\n\n\nMoveIt! is state of the art software for mobile manipulation, incorporating the latest advances in motion planning, manipulation, 3D perception, kinematics, control and navigation. It provides an easy-to-use platform for developing advanced robotics applications, evaluating new robot designs and building integrated robotics products for industrial, commercial, R\nD and other domains.\n-- \nhttp://moveit.ros.org/\n\n\n\n\nFor our project we are using ROS MoveIt! to calculate the inverse kinematics for Roboy. More specifically we need a joint trajectory, that describes how joint angles change over time. This joint trajectoy will be fed into CASPR / CASPROS to simulate / output motor commands. Therefore it is necessary to make use of MoveIt!'s motion planning functionality.\n\n\nInstallation\n\n\nIn the current implementation of the code, Ubuntu 16.04.3 LTS (Xenial Xerus) was used, which only works with ROS Kinetic. In this case, installation is done after the following steps (provided that ROS Kinetic is already installed):\n\n\n\n\nsudo apt-get install ros-kinetic-moveit\n\n\nsource /opt/ros/kinetic/setup.bash\n\n\n\n\nFor further information, go to the \nofficial MoveIt! installation website", 
            "title": "ROS MoveIt!"
        }, 
        {
            "location": "/ros_moveit/#basics", 
            "text": "MoveIt! is state of the art software for mobile manipulation, incorporating the latest advances in motion planning, manipulation, 3D perception, kinematics, control and navigation. It provides an easy-to-use platform for developing advanced robotics applications, evaluating new robot designs and building integrated robotics products for industrial, commercial, R D and other domains.\n--  http://moveit.ros.org/   For our project we are using ROS MoveIt! to calculate the inverse kinematics for Roboy. More specifically we need a joint trajectory, that describes how joint angles change over time. This joint trajectoy will be fed into CASPR / CASPROS to simulate / output motor commands. Therefore it is necessary to make use of MoveIt!'s motion planning functionality.", 
            "title": "Basics"
        }, 
        {
            "location": "/ros_moveit/#installation", 
            "text": "In the current implementation of the code, Ubuntu 16.04.3 LTS (Xenial Xerus) was used, which only works with ROS Kinetic. In this case, installation is done after the following steps (provided that ROS Kinetic is already installed):   sudo apt-get install ros-kinetic-moveit  source /opt/ros/kinetic/setup.bash   For further information, go to the  official MoveIt! installation website", 
            "title": "Installation"
        }, 
        {
            "location": "/ik_system/", 
            "text": "Setup\n\n\nThe code for inverse kinematics is written in a ROS package. This can be downloaded by executing following steps:\n\n\n\n\nopen your terminal in your ROS workspace folder, e.g. \ncatkin_ws/src\n\n\ngit clone https://github.com/poeffie/roboy_ik\n\n\ncd ~/catkin_ws\n\n\ncatkin_make\n\n\nsource ~/catkin_ws/devel/setup.bash\n\n\n\n\nRunning this code requires furthermore\n\n\n\n\nROS MoveIt! installed\n\n\nROS MoveIt! tutorial package installed\n\n\nROS MoveIt! IKFast tool installed\n\n\nPaBiLegs MoveIt! Config\n and corresponding \nIKFast Plugin\n installed\n\n\n\n\nSystem Architecture\n\n\nThe architecture of the implementation is depicted in the following figure.\n\n\nBasically we call the inverse kinematics with a ROS service request. The client makes some preprocessing, which includes status checking, wheater Roboy allows movements at the moment or not. This is still subject of implementation. If a IK movement is possible, the publisher node will be called, that does the actual inverse kinematics calculations and outputs the joint trajectory. Visualizing the movement is optional. In this case it is enabled, so one can investigate the movements of Roboy in Rviz. In addition to the publisher, the client also activates the subscriber node, that subscribes to the joint trajectory topic. The received message will afterwards be converted into a .xml file, that is readable by CASPR and CASPROS for simulating / generating motor commands.\n\n\nIn the following chapters we will go through each of the three main programs, the service implementation, the publisher as well as the subscriber node.", 
            "title": "Setup and Architecture"
        }, 
        {
            "location": "/ik_system/#setup", 
            "text": "The code for inverse kinematics is written in a ROS package. This can be downloaded by executing following steps:   open your terminal in your ROS workspace folder, e.g.  catkin_ws/src  git clone https://github.com/poeffie/roboy_ik  cd ~/catkin_ws  catkin_make  source ~/catkin_ws/devel/setup.bash   Running this code requires furthermore   ROS MoveIt! installed  ROS MoveIt! tutorial package installed  ROS MoveIt! IKFast tool installed  PaBiLegs MoveIt! Config  and corresponding  IKFast Plugin  installed", 
            "title": "Setup"
        }, 
        {
            "location": "/ik_system/#system-architecture", 
            "text": "The architecture of the implementation is depicted in the following figure. \nBasically we call the inverse kinematics with a ROS service request. The client makes some preprocessing, which includes status checking, wheater Roboy allows movements at the moment or not. This is still subject of implementation. If a IK movement is possible, the publisher node will be called, that does the actual inverse kinematics calculations and outputs the joint trajectory. Visualizing the movement is optional. In this case it is enabled, so one can investigate the movements of Roboy in Rviz. In addition to the publisher, the client also activates the subscriber node, that subscribes to the joint trajectory topic. The received message will afterwards be converted into a .xml file, that is readable by CASPR and CASPROS for simulating / generating motor commands.  In the following chapters we will go through each of the three main programs, the service implementation, the publisher as well as the subscriber node.", 
            "title": "System Architecture"
        }, 
        {
            "location": "/server/", 
            "text": "Server Implementation\n\n\nIn the following chapters, the code is described step by step, splitting it into compact blocks to improve readability. The heading will in general be left out, as it only contains \nincludes\n, which does not need further explanations. We start here with the ROS server node, the initializing part for inverse kinematics calulations. The server works together with a so called client, which build together a ROS service.\n\n\nSource:\n The server code can be found \nhere\n\n\nMain\n\n\nroboy_ik_server\n is the name of the server node and \nroboy_ik\n the package name. We initialize a common server as it is taught on the \nofficial ROS Service tutorial\n\n\nint main(int argc, char **argv)\n{\n  ros::init(argc, argv, \nroboy_ik_server\n);\n  ros::NodeHandle n;\n\n  ros::ServiceServer service = n.advertiseService(\nroboy_ik\n, call_ik);\n  ROS_INFO(\nReady to send position request.\n);\n  ros::spin();\n\n  return 0;\n}\n\n\n\n\nCallback\n\n\nThe callback will be executed as soon as a request is detected.\n\nInverseKinematics\n is the name of the .srv file.\nIn the first line we are checking a the sum of \nreq.a\n, \nreq.b\n, and \nreq.c\n. These values are the x, y and z coordinates of the desired position, that is requested by the client. This statement is always true, as the position will for sure not overshoot this value. So basically this is still subject of implementation and should be replaced in the future by a reasonable Roboy state query, that provides Roboy not to execute inverse kinematics, if other subtasks are blocking.\n\n\nbool call_ik(roboy_ik::InverseKinematics::Request  \nreq,\n         roboy_ik::InverseKinematics::Response \nres)\n{\n//TODO: Find a reasonable state query to replace this if / else condition\n  if((req.a + req.b + req.c) \n 10000.0) {\n    res.sum = true;\n    ofstream pose_file;\n    pose_file.open (\n/home/offi/catkin_ws/src/roboy_ik/src/pose.txt\n);\n    pose_file \n std::fixed \n std::setprecision(5) \n req.a \nendl;\n    pose_file \n std::fixed \n std::setprecision(5) \n req.b \nendl;\n    pose_file \n std::fixed \n std::setprecision(5) \n req.c;\n    pose_file.close();\n  }\n  else {\n    res.sum = false;\n  }\n  ROS_INFO(\nrequest: x=%lf, y=%lf, z=%lf\n, (double)req.a, (double)req.b, (double)req.c);\n  ROS_INFO(\nsending back response: [%d]\n, (bool)res.sum);\n  if(res.sum == true) {\n    system(\n/home/offi/catkin_ws/src/roboy_ik/src/run.sh\n);\n  }\n\n  return true;\n}\n\n\n\n\nIf Roboy is allowed to execute the IK, what should basically be done is that the publisher node will receive this values and start calculating the inverse kinematics and finally, if successful, publish the joint trajectory. The upcomming problem here is that the Publisher Node can't be started from another node. It is not possible to define two nodes within one .cpp file, especially not a server and a publisher node.\n\n\nTo call the publisher from a running node and also send a response to the client, which includes information wheather the IK calculations were successful, I came up with the following solution, that may be not optimal but sufficient for prototyping.\n\n\nFirst of all, the pose is stored locally in the file \npose.txt\n. This is the connecting link to share information between service and publisher. Afterwards the system function calls \nrun.sh\n, a .bash file that executes the publisher via .launch file. The code is the following:\n\n\n#!/bin/bash  \nroslaunch roboy_ik motion_planning_api_tutorial.launch\necho \nSuccessfully executed motion planning\n\n\n\n\n\nAs the publisher node has to terminate completely after finishing the calculations, one needs to edit the \nnode\n tags in the \nmotion_planning_api.launch\n, found in \n/catkin_ws/src/roboy_ik/launch\n, to contain required=\"true\" and make respawn=\"false\".", 
            "title": "Server Node"
        }, 
        {
            "location": "/server/#server-implementation", 
            "text": "In the following chapters, the code is described step by step, splitting it into compact blocks to improve readability. The heading will in general be left out, as it only contains  includes , which does not need further explanations. We start here with the ROS server node, the initializing part for inverse kinematics calulations. The server works together with a so called client, which build together a ROS service.  Source:  The server code can be found  here", 
            "title": "Server Implementation"
        }, 
        {
            "location": "/server/#main", 
            "text": "roboy_ik_server  is the name of the server node and  roboy_ik  the package name. We initialize a common server as it is taught on the  official ROS Service tutorial  int main(int argc, char **argv)\n{\n  ros::init(argc, argv,  roboy_ik_server );\n  ros::NodeHandle n;\n\n  ros::ServiceServer service = n.advertiseService( roboy_ik , call_ik);\n  ROS_INFO( Ready to send position request. );\n  ros::spin();\n\n  return 0;\n}", 
            "title": "Main"
        }, 
        {
            "location": "/server/#callback", 
            "text": "The callback will be executed as soon as a request is detected. InverseKinematics  is the name of the .srv file.\nIn the first line we are checking a the sum of  req.a ,  req.b , and  req.c . These values are the x, y and z coordinates of the desired position, that is requested by the client. This statement is always true, as the position will for sure not overshoot this value. So basically this is still subject of implementation and should be replaced in the future by a reasonable Roboy state query, that provides Roboy not to execute inverse kinematics, if other subtasks are blocking.  bool call_ik(roboy_ik::InverseKinematics::Request   req,\n         roboy_ik::InverseKinematics::Response  res)\n{\n//TODO: Find a reasonable state query to replace this if / else condition\n  if((req.a + req.b + req.c)   10000.0) {\n    res.sum = true;\n    ofstream pose_file;\n    pose_file.open ( /home/offi/catkin_ws/src/roboy_ik/src/pose.txt );\n    pose_file   std::fixed   std::setprecision(5)   req.a  endl;\n    pose_file   std::fixed   std::setprecision(5)   req.b  endl;\n    pose_file   std::fixed   std::setprecision(5)   req.c;\n    pose_file.close();\n  }\n  else {\n    res.sum = false;\n  }\n  ROS_INFO( request: x=%lf, y=%lf, z=%lf , (double)req.a, (double)req.b, (double)req.c);\n  ROS_INFO( sending back response: [%d] , (bool)res.sum);\n  if(res.sum == true) {\n    system( /home/offi/catkin_ws/src/roboy_ik/src/run.sh );\n  }\n\n  return true;\n}  If Roboy is allowed to execute the IK, what should basically be done is that the publisher node will receive this values and start calculating the inverse kinematics and finally, if successful, publish the joint trajectory. The upcomming problem here is that the Publisher Node can't be started from another node. It is not possible to define two nodes within one .cpp file, especially not a server and a publisher node.  To call the publisher from a running node and also send a response to the client, which includes information wheather the IK calculations were successful, I came up with the following solution, that may be not optimal but sufficient for prototyping.  First of all, the pose is stored locally in the file  pose.txt . This is the connecting link to share information between service and publisher. Afterwards the system function calls  run.sh , a .bash file that executes the publisher via .launch file. The code is the following:  #!/bin/bash  \nroslaunch roboy_ik motion_planning_api_tutorial.launch\necho  Successfully executed motion planning   As the publisher node has to terminate completely after finishing the calculations, one needs to edit the  node  tags in the  motion_planning_api.launch , found in  /catkin_ws/src/roboy_ik/launch , to contain required=\"true\" and make respawn=\"false\".", 
            "title": "Callback"
        }, 
        {
            "location": "/client/", 
            "text": "Source:\n The client code can be found \nhere\n\n\nMain\n\n\nThe client has almost no modifications to a standard client, apart from saving the pose coordinates as floats with the function \natof()\n. Further explanations can be found on the \nofficial ROS Service tutorial\n\n\nint main(int argc, char **argv)\n{\n  ros::init(argc, argv, \nroboy_ik_client\n);\n\n  if (argc != 4)\n  {\n    ROS_INFO(\nusage: send position X Y Z\n);\n    return 1;\n  }\n  ros::NodeHandle n;\n\n  ros::ServiceClient client = n.serviceClient\nroboy_ik::InverseKinematics\n(\nroboy_ik\n);\n  roboy_ik::InverseKinematics srv;\n  srv.request.a = atof(argv[1]);\n  srv.request.b = atof(argv[2]);\n  srv.request.c = atof(argv[3]);\n  if (client.call(srv))\n  {\n    ROS_INFO(\nInverse Kinematics Success: %s\n, (int)srv.response.sum ? \ntrue\n : \nfalse\n);\n  }\n  else\n  {\n    ROS_ERROR(\nFailed to call inverse kinematics\n);\n    return 1;\n  }\n\n  return 0;\n}", 
            "title": "Client Node"
        }, 
        {
            "location": "/client/#main", 
            "text": "The client has almost no modifications to a standard client, apart from saving the pose coordinates as floats with the function  atof() . Further explanations can be found on the  official ROS Service tutorial  int main(int argc, char **argv)\n{\n  ros::init(argc, argv,  roboy_ik_client );\n\n  if (argc != 4)\n  {\n    ROS_INFO( usage: send position X Y Z );\n    return 1;\n  }\n  ros::NodeHandle n;\n\n  ros::ServiceClient client = n.serviceClient roboy_ik::InverseKinematics ( roboy_ik );\n  roboy_ik::InverseKinematics srv;\n  srv.request.a = atof(argv[1]);\n  srv.request.b = atof(argv[2]);\n  srv.request.c = atof(argv[3]);\n  if (client.call(srv))\n  {\n    ROS_INFO( Inverse Kinematics Success: %s , (int)srv.response.sum ?  true  :  false );\n  }\n  else\n  {\n    ROS_ERROR( Failed to call inverse kinematics );\n    return 1;\n  }\n\n  return 0;\n}", 
            "title": "Main"
        }, 
        {
            "location": "/publisher/", 
            "text": "Source:\n The publisher code can be found \nhere\n\n\nPublisher Implementation\n\n\nThe publisher does the main calculations. As it only has a main function, the code is split up in blocks for better readability. This implementation is based on the official \nMoveIt! Motion Planners Tutorial\n\n\nRobot Model Init\n\n\nWe start by initializing the publisher node, called \nmotion\n. The second step is instantiating a RobotModelLoader object, that looks up the robot description on the ROS parameter server and constructs a RobotModel. What robot model is used as \n\"robot_description\"\n can be seen and edited in the \nmotion_planning_api.launch\n file. This process will be described in a later chapter.\n\n\n// ROS Initilisation\nros::init(argc, argv, \nmotion\n);\nros::AsyncSpinner spinner(1);\nspinner.start();\nros::NodeHandle node_handle(\n~\n);\n// MoveIt! Robot Model Initialisation\nrobot_model_loader::RobotModelLoader robot_model_loader(\nrobot_description\n);\nrobot_model::RobotModelPtr robot_model = robot_model_loader.getModel();\n\n\n\n\nPlanning Init\n\n\nThe PlanningScene maintains the state of the whole world and is created by the \nrobot_model\n. Afterwards the planner is loaded by ROS plugin library. We wil discuss the planner in the IKFast chapter.\n\n\nplanning_scene::PlanningScenePtr planning_scene(new planning_scene::PlanningScene(robot_model));\nboost::scoped_ptr\npluginlib::ClassLoader\nplanning_interface::PlannerManager\n planner_plugin_loader;\nplanning_interface::PlannerManagerPtr planner_instance;\nstd::string planner_plugin_name;\n\n\n\n\nLoading Planning Plugin\n\n\nPlanners are plugins in MoveIt! and you can use the ROS pluginlib interface to load any planner that you want to use.\n\n\n// We get the name of planning plugin we want to load\n// from the ROS param server, and then load the planner\n// making sure to catch all exceptions.\nif (!node_handle.getParam(\nplanning_plugin\n, planner_plugin_name))\n  ROS_FATAL_STREAM(\nCould not find planner plugin name\n);\ntry\n{\n  planner_plugin_loader.reset(new pluginlib::ClassLoader\nplanning_interface::PlannerManager\n(\n      \nmoveit_core\n, \nplanning_interface::PlannerManager\n));\n}\ncatch (pluginlib::PluginlibException\n ex)\n{\n  ROS_FATAL_STREAM(\nException while creating planning plugin loader \n \n ex.what());\n}\ntry\n{\n  planner_instance.reset(planner_plugin_loader-\ncreateUnmanagedInstance(planner_plugin_name));\n  if (!planner_instance-\ninitialize(robot_model, node_handle.getNamespace()))\n    ROS_FATAL_STREAM(\nCould not initialize planner instance\n);\n  ROS_INFO_STREAM(\nUsing planning interface '\n \n planner_instance-\ngetDescription() \n \n'\n);\n}\ncatch (pluginlib::PluginlibException\n ex)\n{\n  const std::vector\nstd::string\n classes = planner_plugin_loader-\ngetDeclaredClasses();\n  std::stringstream ss;\n  for (std::size_t i = 0; i \n classes.size(); ++i)\n    ss \n classes[i] \n \n \n;\n  ROS_ERROR_STREAM(\nException while loading planner '\n \n planner_plugin_name \n \n': \n \n ex.what() \n std::endl\n                                                         \n \nAvailable plugins: \n \n ss.str());\n}\n\n\n\n\nWait to startup Rviz\n\n\nSleeping a little to allow time to startup rviz, etc.\n\n\nros::WallDuration sleep_time(15.0);\nsleep_time.sleep();\n\n\n\n\nDefinitions\n\n\nDefining variables, that will be used later.\n\n\nplanning_interface::MotionPlanRequest req;\nplanning_interface::MotionPlanResponse res;\nplanning_interface::PlanningContextPtr context;\nmoveit_msgs::Constraints pose_goal;\nmoveit_msgs::MotionPlanResponse response;\nmoveit_msgs::DisplayTrajectory display_trajectory;\n\n\n\n\nGet Pose\n\n\nWe receive the pose by opening \npose_file.txt\n and reading out all lines. We do not consider the orientation in this implementation. But this can easyily be modified by making use of the fourth array storage element of \nposes\n.\n\n\nstd::string poses[4];\nifstream pose_file(\n/home/offi/catkin_ws/src/roboy_ik/src/pose.txt\n);\nint i = 0;\nif(!pose_file) \n{\n  cout\nError opening output file\nendl;\n  system(\npause\n);\n  return -1;\n}\nROS_INFO(\nGoal Position (x, y, z):\n);\nwhile(!pose_file.eof())\n{\n  getline(pose_file, poses[i], '\\n');\n  ROS_INFO(\n%s\n, poses[i].c_str());\n}\n\n\n\n\nSet Pose\n\n\nNow we write the pose coordinates to a gemoetry message, that will be used for the motion plan request. The \npose.header.frame_id\n is the coordinate frame of the robot model to which the pose will reference to. Chosing \nodom_combined\n ensures that the end effector moves to the desired pose coordnates, considering point \nodom_combined\n (0, 0, 0) as reference frame.\n\n\n// Sample Pose: 0.03394;  -0.17347;   -0.37346;\ngeometry_msgs::PoseStamped pose;\npose.header.frame_id = \nodom_combined\n;\npose.pose.position.x = atof(poses[0].c_str());\npose.pose.position.y = atof(poses[1].c_str());\npose.pose.position.z = atof(poses[2].c_str());\npose.pose.orientation.w = 1.0;;\n\n\nstd::vector\ndouble\n tolerance_pose(3, 0.01);\nstd::vector\ndouble\n tolerance_angle(3, 0.1);\n\npose_goal = kinematic_constraints::constructGoalConstraints(\npabi_legs__link_0_0\n, pose, tolerance_pose, tolerance_angle);\nreq.group_name = \nleg\n;\nreq.goal_constraints.push_back(pose_goal);\n\n\n\n\nCalculating Inverse Kinematics\n\n\nNow we construct and call a planning context that encapsulate the scene, the request and the response.\n\n\ncontext = planner_instance-\ngetPlanningContext(planning_scene, req, res.error_code_);\ncontext-\nsolve(res);\nif (res.error_code_.val != res.error_code_.SUCCESS)\n{\n  ROS_ERROR(\nCould not compute plan successfully\n);\n  return 0;\n}\n\n\n\n\nVisualizing\n\n\nFinally we visualize the trajectory, which also means publishing the joint trajectory via the topic \n/move_group/display_planned_path\n.\n\n\n/* Visualize the trajectory */\nROS_INFO(\nVisualizing the IK trajectory\n);\n\nros::Publisher display_publisher = node_handle.advertise\nmoveit_msgs::DisplayTrajectory\n(\n/move_group/display_planned_path\n, 1, true);\nres.getMessage(response);\n\ndisplay_trajectory.trajectory_start = response.trajectory_start;\ndisplay_trajectory.trajectory.push_back(response.trajectory);\ndisplay_publisher.publish(display_trajectory);", 
            "title": "Publisher Node"
        }, 
        {
            "location": "/publisher/#publisher-implementation", 
            "text": "The publisher does the main calculations. As it only has a main function, the code is split up in blocks for better readability. This implementation is based on the official  MoveIt! Motion Planners Tutorial", 
            "title": "Publisher Implementation"
        }, 
        {
            "location": "/publisher/#robot-model-init", 
            "text": "We start by initializing the publisher node, called  motion . The second step is instantiating a RobotModelLoader object, that looks up the robot description on the ROS parameter server and constructs a RobotModel. What robot model is used as  \"robot_description\"  can be seen and edited in the  motion_planning_api.launch  file. This process will be described in a later chapter.  // ROS Initilisation\nros::init(argc, argv,  motion );\nros::AsyncSpinner spinner(1);\nspinner.start();\nros::NodeHandle node_handle( ~ );\n// MoveIt! Robot Model Initialisation\nrobot_model_loader::RobotModelLoader robot_model_loader( robot_description );\nrobot_model::RobotModelPtr robot_model = robot_model_loader.getModel();", 
            "title": "Robot Model Init"
        }, 
        {
            "location": "/publisher/#planning-init", 
            "text": "The PlanningScene maintains the state of the whole world and is created by the  robot_model . Afterwards the planner is loaded by ROS plugin library. We wil discuss the planner in the IKFast chapter.  planning_scene::PlanningScenePtr planning_scene(new planning_scene::PlanningScene(robot_model));\nboost::scoped_ptr pluginlib::ClassLoader planning_interface::PlannerManager  planner_plugin_loader;\nplanning_interface::PlannerManagerPtr planner_instance;\nstd::string planner_plugin_name;", 
            "title": "Planning Init"
        }, 
        {
            "location": "/publisher/#loading-planning-plugin", 
            "text": "Planners are plugins in MoveIt! and you can use the ROS pluginlib interface to load any planner that you want to use.  // We get the name of planning plugin we want to load\n// from the ROS param server, and then load the planner\n// making sure to catch all exceptions.\nif (!node_handle.getParam( planning_plugin , planner_plugin_name))\n  ROS_FATAL_STREAM( Could not find planner plugin name );\ntry\n{\n  planner_plugin_loader.reset(new pluginlib::ClassLoader planning_interface::PlannerManager (\n       moveit_core ,  planning_interface::PlannerManager ));\n}\ncatch (pluginlib::PluginlibException  ex)\n{\n  ROS_FATAL_STREAM( Exception while creating planning plugin loader     ex.what());\n}\ntry\n{\n  planner_instance.reset(planner_plugin_loader- createUnmanagedInstance(planner_plugin_name));\n  if (!planner_instance- initialize(robot_model, node_handle.getNamespace()))\n    ROS_FATAL_STREAM( Could not initialize planner instance );\n  ROS_INFO_STREAM( Using planning interface '    planner_instance- getDescription()    ' );\n}\ncatch (pluginlib::PluginlibException  ex)\n{\n  const std::vector std::string  classes = planner_plugin_loader- getDeclaredClasses();\n  std::stringstream ss;\n  for (std::size_t i = 0; i   classes.size(); ++i)\n    ss   classes[i]      ;\n  ROS_ERROR_STREAM( Exception while loading planner '    planner_plugin_name    ':     ex.what()   std::endl\n                                                            Available plugins:     ss.str());\n}", 
            "title": "Loading Planning Plugin"
        }, 
        {
            "location": "/publisher/#wait-to-startup-rviz", 
            "text": "Sleeping a little to allow time to startup rviz, etc.  ros::WallDuration sleep_time(15.0);\nsleep_time.sleep();", 
            "title": "Wait to startup Rviz"
        }, 
        {
            "location": "/publisher/#definitions", 
            "text": "Defining variables, that will be used later.  planning_interface::MotionPlanRequest req;\nplanning_interface::MotionPlanResponse res;\nplanning_interface::PlanningContextPtr context;\nmoveit_msgs::Constraints pose_goal;\nmoveit_msgs::MotionPlanResponse response;\nmoveit_msgs::DisplayTrajectory display_trajectory;", 
            "title": "Definitions"
        }, 
        {
            "location": "/publisher/#get-pose", 
            "text": "We receive the pose by opening  pose_file.txt  and reading out all lines. We do not consider the orientation in this implementation. But this can easyily be modified by making use of the fourth array storage element of  poses .  std::string poses[4];\nifstream pose_file( /home/offi/catkin_ws/src/roboy_ik/src/pose.txt );\nint i = 0;\nif(!pose_file) \n{\n  cout Error opening output file endl;\n  system( pause );\n  return -1;\n}\nROS_INFO( Goal Position (x, y, z): );\nwhile(!pose_file.eof())\n{\n  getline(pose_file, poses[i], '\\n');\n  ROS_INFO( %s , poses[i].c_str());\n}", 
            "title": "Get Pose"
        }, 
        {
            "location": "/publisher/#set-pose", 
            "text": "Now we write the pose coordinates to a gemoetry message, that will be used for the motion plan request. The  pose.header.frame_id  is the coordinate frame of the robot model to which the pose will reference to. Chosing  odom_combined  ensures that the end effector moves to the desired pose coordnates, considering point  odom_combined  (0, 0, 0) as reference frame.  // Sample Pose: 0.03394;  -0.17347;   -0.37346;\ngeometry_msgs::PoseStamped pose;\npose.header.frame_id =  odom_combined ;\npose.pose.position.x = atof(poses[0].c_str());\npose.pose.position.y = atof(poses[1].c_str());\npose.pose.position.z = atof(poses[2].c_str());\npose.pose.orientation.w = 1.0;;\n\n\nstd::vector double  tolerance_pose(3, 0.01);\nstd::vector double  tolerance_angle(3, 0.1);\n\npose_goal = kinematic_constraints::constructGoalConstraints( pabi_legs__link_0_0 , pose, tolerance_pose, tolerance_angle);\nreq.group_name =  leg ;\nreq.goal_constraints.push_back(pose_goal);", 
            "title": "Set Pose"
        }, 
        {
            "location": "/publisher/#calculating-inverse-kinematics", 
            "text": "Now we construct and call a planning context that encapsulate the scene, the request and the response.  context = planner_instance- getPlanningContext(planning_scene, req, res.error_code_);\ncontext- solve(res);\nif (res.error_code_.val != res.error_code_.SUCCESS)\n{\n  ROS_ERROR( Could not compute plan successfully );\n  return 0;\n}", 
            "title": "Calculating Inverse Kinematics"
        }, 
        {
            "location": "/publisher/#visualizing", 
            "text": "Finally we visualize the trajectory, which also means publishing the joint trajectory via the topic  /move_group/display_planned_path .  /* Visualize the trajectory */\nROS_INFO( Visualizing the IK trajectory );\n\nros::Publisher display_publisher = node_handle.advertise moveit_msgs::DisplayTrajectory ( /move_group/display_planned_path , 1, true);\nres.getMessage(response);\n\ndisplay_trajectory.trajectory_start = response.trajectory_start;\ndisplay_trajectory.trajectory.push_back(response.trajectory);\ndisplay_publisher.publish(display_trajectory);", 
            "title": "Visualizing"
        }, 
        {
            "location": "/subscriber/", 
            "text": "Source:\n The subscriber code can be found \nhere\n\n\nNote:\n There have to be done some fixes marked with TODO, as the code, like it is presented here, was optimized for the PaBiLegs model on CASPR. The model there uses 6 joints for visualizing the geometry of the legs better. But actually it only needs two links and two joints, as our planning group for PaBiLegs Ik and therefore the trajectory output only outputs two joint values per waypoint. So I made some modifications. These can be undone easily or one can use the universally applicable subscriber code, added in the roboy_ik package and named traj_sub_uni.cpp.\n\n\nMain\n\n\nWe start with the main function. The main function is completely basic and subscribes to the topic \n/move_group/display_planned_path\n, that is published by the publisher node \nmotion\n.\n\n\nint main(int argc, char **argv)\n{\n  ros::init(argc, argv, \nsubscribe_trajectory\n);\n  ros::NodeHandle n;\n  ros::Subscriber traj_sub = n.subscribe(\n/move_group/display_planned_path\n, 1000, traj_sub_callback);\n  ros::spin();\n  return 0;\n}\n\n\n\n\nCallback\n\n\nAs soon as message from the topic is sent out and recognized, the code jumps into the subscriber callback. Here we basically read out the trajectory values and store them into an 2D array. The array has a predefined size. \nNUM_WAYPOINTS\n is the number of waypoints, the trajectory consits of. This value varies, based on how much the new pose differs from the original one. This means that one has to read out the length of the trajectory to define the array size. Unfortunately this problem could not be solved yet, so that it is still subjet of implementation.\n\n\nvoid traj_sub_callback(const moveit_msgs::DisplayTrajectory::ConstPtr\n msg)\n{\n    const trajectory_msgs::JointTrajectory traj = msg-\ntrajectory[0].joint_trajectory;\n    // TODO: Get length of trajectoy / number of waypoints and replace NUM_WAYPOINTS \n    // with the resulting variable\n    double joint_traj_array[NUM_WAYPOINTS][NUM_JOINTS];\n    for (int i = 0; i \n NUM_WAYPOINTS; i++) {\n        for(int j = 0; j \n NUM_JOINTS; j++) {\n            // TODO: remove this, if all joints are used. This condition is for experimental\n            // purposes. Keep it, if just e.g. the first two will be used, as it is the case\n            // for the PaBiLegs demonstration\n            if (j \n= 2) {\n                joint_traj_array[i][j] = 0.0;\n            }\n            else {\n                joint_traj_array[i][j] = traj.points[i].positions[j];\n            }\n            ROS_INFO(\nArray value: [%f]\n, joint_traj_array[i][j]);\n        }\n        ROS_INFO(\n \n);\n    }\n    /**\n     * Call a function to write the trajectory values into a .xml file.\n     */\n    write_joint_trajectory_xml(joint_traj_array);\n\n}\n\n\n\n\n\nCreating XML\n\n\nWriting the values from the array into an .xml file is done in this function. In general we use the opensource C++ plugin \ntinyXML\n here to generate our file. Instead of splitting up this comparably long function into multiple blocks, as it was done for the publisher node, we keep here the formatation and explain the functionality mainly inside of the code by some comments.\n\n\nvoid write_joint_trajectory_xml (double q_array[NUM_WAYPOINTS][NUM_JOINTS]) {\n        int i = 0;\n\n        ROS_INFO(\nIN CALLBACk222!!!\n);\n        TiXmlDocument doc;\n\n        TiXmlElement * root = new TiXmlElement( \ntrajectories\n );\n        doc.LinkEndChild( root );\n\n        TiXmlElement * cxn = new TiXmlElement( \nquintic_spline_trajectory\n );\n        root-\nLinkEndChild( cxn );\n        cxn-\nSetAttribute(\nid\n, \ntraj_test2\n);\n        cxn-\nSetAttribute(\ntime_definition\n, \nabsolute\n);\n        cxn-\nSetAttribute(\ntime_step\n, \n0.00667\n);\n\n        TiXmlElement * pts = new TiXmlElement( \npoints\n );\n        cxn-\nLinkEndChild( pts );\n\n        TiXmlElement * point = new TiXmlElement( \npoint\n );\n        pts-\nLinkEndChild( point );\n        /**\n         * In this state of development I have not yet implemented the conversion from array\n         * data to joint strings. This will be the next step. So far, I just set all the joint\n         * values to 0.\n         */\n        TiXmlElement * q = new TiXmlElement( \nq\n );\n        point-\nLinkEndChild( q );\n        TiXmlText * q_values = new TiXmlText( get_joint_string(q_array, i) );\n        q-\nLinkEndChild( q_values );\n\n        TiXmlElement * q_dot = new TiXmlElement( \nq_dot\n );\n        point-\nLinkEndChild( q_dot );\n        TiXmlText * q_dot_values = new TiXmlText( \n0.0 0.0 0.0 0.0 0.0 0.0\n  );\n        q_dot-\nLinkEndChild( q_dot_values );\n\n        TiXmlElement * q_ddot = new TiXmlElement( \nq_ddot\n );\n        point-\nLinkEndChild( q_ddot );\n        TiXmlText * q_ddot_values = new TiXmlText( \n0.0 0.0 0.0 0.0 0.0 0.0\n  );\n        q_ddot-\nLinkEndChild( q_ddot_values );\n        /**\n         * If the trajectory consits of more than one point, this loop will be called.\n         * The first point of a trajectory and the following ones differ by the point-attribute\n         * time, that is set here.\n         */\n        if (IS_TRAJECTORY == 1)\n        {\n                for (double i = 1; i \n NUM_WAYPOINTS; i++) {\n                        TiXmlElement * point = new TiXmlElement( \npoint\n );\n                        pts-\nLinkEndChild( point );\n\n                        TiXmlElement * q = new TiXmlElement( \nq\n );\n                        point-\nLinkEndChild( q );\n                        point-\nSetAttribute(\ntime\n, to_string(i/10));\n                        TiXmlText * q_values = new TiXmlText( get_joint_string(q_array, i)  );\n                        q-\nLinkEndChild( q_values );\n\n                        TiXmlElement * q_dot = new TiXmlElement( \nq_dot\n );\n                        point-\nLinkEndChild( q_dot );\n                        // TODO: replace \n0.0 0.0 0.0 0.0 0.0 0.0\n by get_joint_string(q_array, i)\n                        // if you want to have full functionalty. This is just for experimental\n                        // purposes, as the PaBiLegs CASPR model has 6 joints, instead of 2.\n                        TiXmlText * q_dot_values = new TiXmlText( \n0.0 0.0 0.0 0.0 0.0 0.0\n  );\n                        q_dot-\nLinkEndChild( q_dot_values );\n\n                        TiXmlElement * q_ddot = new TiXmlElement( \nq_ddot\n );\n                        point-\nLinkEndChild( q_ddot );\n                        // TODO: replace \n0.0 0.0 0.0 0.0 0.0 0.0\n by get_joint_string(q_array, i)\n                        // if you want to have full functionalty. This is just for experimental\n                        // purposes, as the PaBiLegs CASPR model has 6 joints, instead of 2.\n                        TiXmlText * q_ddot_values = new TiXmlText( \n0.0 0.0 0.0 0.0 0.0 0.0\n  );\n                        q_ddot-\nLinkEndChild( q_ddot_values );\n                }\n        }\n        /**\n         * tinyXML does not parse DOCTYPE elements. CASPR/OS needs a DOCTYPE declaration.\n         * The doctype declaration never changes for any trajectory, so I created an XML file, called\n         * head, containing the top of a trajectory XML file, that never changes.\n         * trajo.xml is the part of the trajectory that contains the individual joint angles\n         * we read from ROS MoveIt. Therefore it has to be generated seperately and combined\n         * afterwards with the head.xml\n         * trajo_combined.xml is the final usable trajectory file for CASPR / CASPROS\n         */\n\n        // TODO: change the file path for trajo.xml, head.xml, trajo_combined.xml as you wish.\n        doc.SaveFile( \n/home/offi/catkin_ws/src/roboy_ik/src/trajo.xml\n );\n        ifstream file1( \n/home/offi/catkin_ws/src/roboy_ik/src/head.xml\n ) ;\n        ifstream file2( \n/home/offi/catkin_ws/src/roboy_ik/src/trajo.xml\n ) ;\n        ofstream combined_file( \n/home/offi/catkin_ws/src/roboy_ik/src/trajo_combined.xml\n );\n        combined_file \n file1.rdbuf() \n file2.rdbuf();\n\n        ifstream  src(\n/home/offi/catkin_ws/src/roboy_ik/src/trajo_combined.xml\n, std::ios::binary);\n        // TODO: change the file path to the CASPR model accordingly\n        ofstream  dst(\n/home/offi/CASPR-master/data/model_config/models/PaBiLegs/PaBiLegs_trajectories.xml\n,   std::ios::binary);\n\n        dst \n src.rdbuf();\n        ROS_INFO(\nTrajectory successfully created!\n);\n}\n\n\n\n\nGet Joint String\n\n\nThis function generates a joint string out of the array values, as it can be seen in the code above, where we have 6 joints and each joint has the value of zero: \n\"0.0 0.0 0.0 0.0 0.0 0.0\"\n. The values can, but do not absolutely need to be seperated by commas.\n\n\nstring get_joint_string(double q_array[NUM_WAYPOINTS][NUM_JOINTS], int wp){\n    stringstream stream;\n    for (int i = 0; i \n NUM_JOINTS; i++){\n        stream \n q_array[wp][i];\n        if (i != NUM_JOINTS-1) {\n            stream \n \n, \n;\n        }\n    }\n    return stream.str();\n}", 
            "title": "Subscriber Node"
        }, 
        {
            "location": "/subscriber/#main", 
            "text": "We start with the main function. The main function is completely basic and subscribes to the topic  /move_group/display_planned_path , that is published by the publisher node  motion .  int main(int argc, char **argv)\n{\n  ros::init(argc, argv,  subscribe_trajectory );\n  ros::NodeHandle n;\n  ros::Subscriber traj_sub = n.subscribe( /move_group/display_planned_path , 1000, traj_sub_callback);\n  ros::spin();\n  return 0;\n}", 
            "title": "Main"
        }, 
        {
            "location": "/subscriber/#callback", 
            "text": "As soon as message from the topic is sent out and recognized, the code jumps into the subscriber callback. Here we basically read out the trajectory values and store them into an 2D array. The array has a predefined size.  NUM_WAYPOINTS  is the number of waypoints, the trajectory consits of. This value varies, based on how much the new pose differs from the original one. This means that one has to read out the length of the trajectory to define the array size. Unfortunately this problem could not be solved yet, so that it is still subjet of implementation.  void traj_sub_callback(const moveit_msgs::DisplayTrajectory::ConstPtr  msg)\n{\n    const trajectory_msgs::JointTrajectory traj = msg- trajectory[0].joint_trajectory;\n    // TODO: Get length of trajectoy / number of waypoints and replace NUM_WAYPOINTS \n    // with the resulting variable\n    double joint_traj_array[NUM_WAYPOINTS][NUM_JOINTS];\n    for (int i = 0; i   NUM_WAYPOINTS; i++) {\n        for(int j = 0; j   NUM_JOINTS; j++) {\n            // TODO: remove this, if all joints are used. This condition is for experimental\n            // purposes. Keep it, if just e.g. the first two will be used, as it is the case\n            // for the PaBiLegs demonstration\n            if (j  = 2) {\n                joint_traj_array[i][j] = 0.0;\n            }\n            else {\n                joint_traj_array[i][j] = traj.points[i].positions[j];\n            }\n            ROS_INFO( Array value: [%f] , joint_traj_array[i][j]);\n        }\n        ROS_INFO(   );\n    }\n    /**\n     * Call a function to write the trajectory values into a .xml file.\n     */\n    write_joint_trajectory_xml(joint_traj_array);\n\n}", 
            "title": "Callback"
        }, 
        {
            "location": "/subscriber/#creating-xml", 
            "text": "Writing the values from the array into an .xml file is done in this function. In general we use the opensource C++ plugin  tinyXML  here to generate our file. Instead of splitting up this comparably long function into multiple blocks, as it was done for the publisher node, we keep here the formatation and explain the functionality mainly inside of the code by some comments.  void write_joint_trajectory_xml (double q_array[NUM_WAYPOINTS][NUM_JOINTS]) {\n        int i = 0;\n\n        ROS_INFO( IN CALLBACk222!!! );\n        TiXmlDocument doc;\n\n        TiXmlElement * root = new TiXmlElement(  trajectories  );\n        doc.LinkEndChild( root );\n\n        TiXmlElement * cxn = new TiXmlElement(  quintic_spline_trajectory  );\n        root- LinkEndChild( cxn );\n        cxn- SetAttribute( id ,  traj_test2 );\n        cxn- SetAttribute( time_definition ,  absolute );\n        cxn- SetAttribute( time_step ,  0.00667 );\n\n        TiXmlElement * pts = new TiXmlElement(  points  );\n        cxn- LinkEndChild( pts );\n\n        TiXmlElement * point = new TiXmlElement(  point  );\n        pts- LinkEndChild( point );\n        /**\n         * In this state of development I have not yet implemented the conversion from array\n         * data to joint strings. This will be the next step. So far, I just set all the joint\n         * values to 0.\n         */\n        TiXmlElement * q = new TiXmlElement(  q  );\n        point- LinkEndChild( q );\n        TiXmlText * q_values = new TiXmlText( get_joint_string(q_array, i) );\n        q- LinkEndChild( q_values );\n\n        TiXmlElement * q_dot = new TiXmlElement(  q_dot  );\n        point- LinkEndChild( q_dot );\n        TiXmlText * q_dot_values = new TiXmlText(  0.0 0.0 0.0 0.0 0.0 0.0   );\n        q_dot- LinkEndChild( q_dot_values );\n\n        TiXmlElement * q_ddot = new TiXmlElement(  q_ddot  );\n        point- LinkEndChild( q_ddot );\n        TiXmlText * q_ddot_values = new TiXmlText(  0.0 0.0 0.0 0.0 0.0 0.0   );\n        q_ddot- LinkEndChild( q_ddot_values );\n        /**\n         * If the trajectory consits of more than one point, this loop will be called.\n         * The first point of a trajectory and the following ones differ by the point-attribute\n         * time, that is set here.\n         */\n        if (IS_TRAJECTORY == 1)\n        {\n                for (double i = 1; i   NUM_WAYPOINTS; i++) {\n                        TiXmlElement * point = new TiXmlElement(  point  );\n                        pts- LinkEndChild( point );\n\n                        TiXmlElement * q = new TiXmlElement(  q  );\n                        point- LinkEndChild( q );\n                        point- SetAttribute( time , to_string(i/10));\n                        TiXmlText * q_values = new TiXmlText( get_joint_string(q_array, i)  );\n                        q- LinkEndChild( q_values );\n\n                        TiXmlElement * q_dot = new TiXmlElement(  q_dot  );\n                        point- LinkEndChild( q_dot );\n                        // TODO: replace  0.0 0.0 0.0 0.0 0.0 0.0  by get_joint_string(q_array, i)\n                        // if you want to have full functionalty. This is just for experimental\n                        // purposes, as the PaBiLegs CASPR model has 6 joints, instead of 2.\n                        TiXmlText * q_dot_values = new TiXmlText(  0.0 0.0 0.0 0.0 0.0 0.0   );\n                        q_dot- LinkEndChild( q_dot_values );\n\n                        TiXmlElement * q_ddot = new TiXmlElement(  q_ddot  );\n                        point- LinkEndChild( q_ddot );\n                        // TODO: replace  0.0 0.0 0.0 0.0 0.0 0.0  by get_joint_string(q_array, i)\n                        // if you want to have full functionalty. This is just for experimental\n                        // purposes, as the PaBiLegs CASPR model has 6 joints, instead of 2.\n                        TiXmlText * q_ddot_values = new TiXmlText(  0.0 0.0 0.0 0.0 0.0 0.0   );\n                        q_ddot- LinkEndChild( q_ddot_values );\n                }\n        }\n        /**\n         * tinyXML does not parse DOCTYPE elements. CASPR/OS needs a DOCTYPE declaration.\n         * The doctype declaration never changes for any trajectory, so I created an XML file, called\n         * head, containing the top of a trajectory XML file, that never changes.\n         * trajo.xml is the part of the trajectory that contains the individual joint angles\n         * we read from ROS MoveIt. Therefore it has to be generated seperately and combined\n         * afterwards with the head.xml\n         * trajo_combined.xml is the final usable trajectory file for CASPR / CASPROS\n         */\n\n        // TODO: change the file path for trajo.xml, head.xml, trajo_combined.xml as you wish.\n        doc.SaveFile(  /home/offi/catkin_ws/src/roboy_ik/src/trajo.xml  );\n        ifstream file1(  /home/offi/catkin_ws/src/roboy_ik/src/head.xml  ) ;\n        ifstream file2(  /home/offi/catkin_ws/src/roboy_ik/src/trajo.xml  ) ;\n        ofstream combined_file(  /home/offi/catkin_ws/src/roboy_ik/src/trajo_combined.xml  );\n        combined_file   file1.rdbuf()   file2.rdbuf();\n\n        ifstream  src( /home/offi/catkin_ws/src/roboy_ik/src/trajo_combined.xml , std::ios::binary);\n        // TODO: change the file path to the CASPR model accordingly\n        ofstream  dst( /home/offi/CASPR-master/data/model_config/models/PaBiLegs/PaBiLegs_trajectories.xml ,   std::ios::binary);\n\n        dst   src.rdbuf();\n        ROS_INFO( Trajectory successfully created! );\n}", 
            "title": "Creating XML"
        }, 
        {
            "location": "/subscriber/#get-joint-string", 
            "text": "This function generates a joint string out of the array values, as it can be seen in the code above, where we have 6 joints and each joint has the value of zero:  \"0.0 0.0 0.0 0.0 0.0 0.0\" . The values can, but do not absolutely need to be seperated by commas.  string get_joint_string(double q_array[NUM_WAYPOINTS][NUM_JOINTS], int wp){\n    stringstream stream;\n    for (int i = 0; i   NUM_JOINTS; i++){\n        stream   q_array[wp][i];\n        if (i != NUM_JOINTS-1) {\n            stream    ,  ;\n        }\n    }\n    return stream.str();\n}", 
            "title": "Get Joint String"
        }, 
        {
            "location": "/experimental/", 
            "text": "Source:\n \nExperimental Code\n\n\nTesting The Code\n\n\nFor planning IK it is necessary to make position request, that are reachable. Especially if your robot has a complex kinematics, it is not recommended to simply guess any position and test them until one of them is reachable. This is the reason why I also wrote another piece of code, that combines the existing Publisher node with some forward kinematics lines. The code can be found \nhere\n. You can use it by simply overwriting the \nmotion.cpp\n or by adding it as an additional node to the package. As the experimental code is pretty long and repeats several lines, that were already discussed in the publisher chapter, I will give here just a short explanation of what code does. There are furthermore some comments, that should help understanding the details. For further information about forward kinematics visit the \n official MoveIt! Kinematic Model tutorial\n.\n\n\nWhat the experimental basically does, is calculating forward kinematics first for some hardcoded joint angles. You can change them easily to try out other positions. This forward kinematics will be visualized in Rviz and looped for several seconds. I save the final position of the end effector and print it with ROS_INFO. \n\n\nIn the next step IK will be executed. You can set the position to reach accordingly to the coordinates, that were calculated by the forward kinematics. The IK should now theoretically reach that position and output another trajectory, that is not identical wit the forward kinematics one. The position of the end effector will be printed here as well. Setting the tolerances may lead to pretty varying results.\n\n\nIssues\n\n\nActually there is an issue, that could not be fixed yet. The IK part will most likely put out an error warning, that no solution could be found. Most likely, because sometimes it works for some reasons, even without changing any parameters / lines of code. Following figure shows the typical error. The image below shows how it looked like, when IK worked.\n\n\nError message\n\n\n\nWorking IK", 
            "title": "Experimental"
        }, 
        {
            "location": "/experimental/#testing-the-code", 
            "text": "For planning IK it is necessary to make position request, that are reachable. Especially if your robot has a complex kinematics, it is not recommended to simply guess any position and test them until one of them is reachable. This is the reason why I also wrote another piece of code, that combines the existing Publisher node with some forward kinematics lines. The code can be found  here . You can use it by simply overwriting the  motion.cpp  or by adding it as an additional node to the package. As the experimental code is pretty long and repeats several lines, that were already discussed in the publisher chapter, I will give here just a short explanation of what code does. There are furthermore some comments, that should help understanding the details. For further information about forward kinematics visit the   official MoveIt! Kinematic Model tutorial .  What the experimental basically does, is calculating forward kinematics first for some hardcoded joint angles. You can change them easily to try out other positions. This forward kinematics will be visualized in Rviz and looped for several seconds. I save the final position of the end effector and print it with ROS_INFO.   In the next step IK will be executed. You can set the position to reach accordingly to the coordinates, that were calculated by the forward kinematics. The IK should now theoretically reach that position and output another trajectory, that is not identical wit the forward kinematics one. The position of the end effector will be printed here as well. Setting the tolerances may lead to pretty varying results.", 
            "title": "Testing The Code"
        }, 
        {
            "location": "/experimental/#issues", 
            "text": "Actually there is an issue, that could not be fixed yet. The IK part will most likely put out an error warning, that no solution could be found. Most likely, because sometimes it works for some reasons, even without changing any parameters / lines of code. Following figure shows the typical error. The image below shows how it looked like, when IK worked. \nError message  \nWorking IK", 
            "title": "Issues"
        }, 
        {
            "location": "/pysdf/", 
            "text": "From SDF to URDF\n\n\nROS MoveIt! needs the robot model to be described in URDF. This could be a problem for several robot models, as it is not guaranteed to have your robot already converted into URDF, as it was the case for Roboy. This is why I will explain in this chapter how I converted .sdf files into URDF.\n\n\nInstall pysdf\n\n\nFirst step is to install pysdf. This is a ROS package, that allows easy conversion from sdf to URDF. Go into your catkin_ws folder and execute following commands:\n\n\n\n\ngit clone https://github.com/andreasBihlmaier/pysdf\n\n\ncd ..\n\n\ncatkin_make\n\n\nsource ~/catkin_ws/devel/setup.bash\n\n\n\n\nExecute pysdf\n\n\n\n\nThis step is optional, but I recommend to backup your robot's .sdf files.\n\n\nNow go into your robot model folder and open a terminal there.\n\n\nExecute \nrosrun pysdf sdf2urdf.py model.sdf model.urdf\n, where model.sdf should be the sdf name of your robot. Typically there is also a \nmodel.config\n in the same directory. The output of the command would be in this case \nmodel.urdf\n, but you can also give it another name.\n\n\nOPTIONAL: If you want to use pysdf without ROS, you can also open the scripts directory of the package. Copy your \nmodel.sdf\n and \nmodel.config\n there and execute: \npython sdf2urdf.py model.sdf model.urdf\n\n\nYou will most likely get the warning message \nCould not find mesh ...\n, no matter what method you used. This is completely normal if you are using meshes in your model.\n\n\nThe Error could look like this.\n\n\nWhat I did now to solve this issue is that I saved my meshes folder in a package that is known by ROS, e.g. \npabi_ik\n or the pysdf package, as I did it in my implementation for instance. Just copy your meshes there and edit the path to these meshes in the generated URDF file accordingly.\n\n\nLast step, but a very important one, is to check your URDF file and edit false values. ROS MoveIt! won't work with your URDF if it contains values that are extremely high. I often figured out, that some values were set to \n1.79769e+308\n. I most likely find them in the line \nlimit effort=\"-1.0\" lower=\"-1.79769e+308\" upper=\"1.79769e+308\" velocity=\"-1.0\"/\n Change them to 0 for instance. I also changed effort and velocity to 0.0 to make my URDF models work.\n\n\n\n\nMoveIt! Config\n\n\nTo get familiar with the ROS MoveIt! model configuration I want to refer to the offical \nMoveIt! setup_assisant_tutorial", 
            "title": "Robot Models"
        }, 
        {
            "location": "/pysdf/#from-sdf-to-urdf", 
            "text": "ROS MoveIt! needs the robot model to be described in URDF. This could be a problem for several robot models, as it is not guaranteed to have your robot already converted into URDF, as it was the case for Roboy. This is why I will explain in this chapter how I converted .sdf files into URDF.", 
            "title": "From SDF to URDF"
        }, 
        {
            "location": "/pysdf/#install-pysdf", 
            "text": "First step is to install pysdf. This is a ROS package, that allows easy conversion from sdf to URDF. Go into your catkin_ws folder and execute following commands:   git clone https://github.com/andreasBihlmaier/pysdf  cd ..  catkin_make  source ~/catkin_ws/devel/setup.bash", 
            "title": "Install pysdf"
        }, 
        {
            "location": "/pysdf/#execute-pysdf", 
            "text": "This step is optional, but I recommend to backup your robot's .sdf files.  Now go into your robot model folder and open a terminal there.  Execute  rosrun pysdf sdf2urdf.py model.sdf model.urdf , where model.sdf should be the sdf name of your robot. Typically there is also a  model.config  in the same directory. The output of the command would be in this case  model.urdf , but you can also give it another name.  OPTIONAL: If you want to use pysdf without ROS, you can also open the scripts directory of the package. Copy your  model.sdf  and  model.config  there and execute:  python sdf2urdf.py model.sdf model.urdf  You will most likely get the warning message  Could not find mesh ... , no matter what method you used. This is completely normal if you are using meshes in your model. \nThe Error could look like this.  What I did now to solve this issue is that I saved my meshes folder in a package that is known by ROS, e.g.  pabi_ik  or the pysdf package, as I did it in my implementation for instance. Just copy your meshes there and edit the path to these meshes in the generated URDF file accordingly.  Last step, but a very important one, is to check your URDF file and edit false values. ROS MoveIt! won't work with your URDF if it contains values that are extremely high. I often figured out, that some values were set to  1.79769e+308 . I most likely find them in the line  limit effort=\"-1.0\" lower=\"-1.79769e+308\" upper=\"1.79769e+308\" velocity=\"-1.0\"/  Change them to 0 for instance. I also changed effort and velocity to 0.0 to make my URDF models work.", 
            "title": "Execute pysdf"
        }, 
        {
            "location": "/pysdf/#moveit-config", 
            "text": "To get familiar with the ROS MoveIt! model configuration I want to refer to the offical  MoveIt! setup_assisant_tutorial", 
            "title": "MoveIt! Config"
        }, 
        {
            "location": "/issues/", 
            "text": "Limit of KDL Solver\n\n\nThe ROS MoveIt! KDL solver is only suitable for use with 6 or more DoF kinematic chains. This is an issue that normally would make IK on the PaBiLegs impossible, as this model only has 2 DoF.\n\n\nTo overcome these limitations, MoveIt! allows to use another solver, the so called IKFast solver, which is capable of solving IK equations analytically of any kinematic chain. It even needs less time for the same problem as KDL. IKFast is provided by Rosen Diankov's \nOpenRAVE\n (Open Robotics Automation Virtual Environment).\n\n\nInstall IKFast\n\n\nOpenRAVE Workstation\n\n\nOpenRave for Ubuntu 16.04 Xenial can be downloaded as a robotic workstation by following this \ntutorial\n. Unfortunately many compiling errors occured during all of my attempts. Using the workstation with a graphical visualization by OpenSceneGraph, as it is described in the tutorial, may however not be necessary for this project, as ROS MoveIt! offers an own solution.\n\n\nMoveIt! IKFast\n\n\nMoveIt! IKFast is the name of a MoveIt! tool that helps to generate a IKFast Plugin, that can replace solvers like the KDL solver. There are two ways to install this tool for ROS kinetic.\n\n\nBinary Install\n:\n\n\nsudo apt-get install ros-kinetic-moveit-kinematics\n\n\nSource\n (inside your catkin workspace):\n\n\ngit clone https://github.com/ros-planning/moveit.git\n\n\nCreate IKFast Plugin\n\n\nIs MoveIt! IKFast successfully installed you can start generating your own IKFast solver plugin. In general there are some steps, that have to be done every time you do this for your robot model.\nFirst of all you need to clarify about these descriptions of your robot:\n\n\n\n\nrobot name (\nrobotname\n): This is the name of your robot, as it is clarified in your URDF.\n\n\nplanning group name (\npl\n): The planning group\n\n\nIKFast output path (\nikpath\n): The path to the C++ file, that will be generated by IKFast and contain the analytical calculations to solve inverse kinematics.\n\n\nMoveIt! IKFast plugin package (\nikpkg\n): The name of your final IKFast Plugin-\n\n\nMoveIt! robot config (\nrobot_config\n): The name of the config package you created for your robot\n\n\n\n\nIKFast Plugin Creation Step by Step:\n\n\n1.)\n Create a working robot URDF file, as described in the \"Robot Models\" chapter\n\n\n2.)\n Load this URDF in the MoveIt! setup_assisant by running \nroslaunch moveit_setup_assistant setup_assistant.launch\n\n\n3.)\n (\nOPTIONAL\n - if you haven't done it before) Create a new working MoveiIt! Config plugin. Remember the name of planning group and in the last step \n\"Configuration files\"\n chose the folder of your workspace as output path. Now edit this path by adding \n/\nrobotname\n_moveit_config\n. This will be the name of your config package. From now on, we will reference \nrobotname\n_moveit_config\n as \nrobot_config\n. Execute \ncatkin_make\n to build the package.\n\n\n4.)\n Navigate into the folder, where the URDF of your robot is saved. Open your terminal here and execute:\n\n\nrosrun collada_urdf urdf_to_collada \nrobotname\n.urdf \nrobotname\n.dae\n\n\n\n\nThis will generate an .dae file out of the URDF\n\n\n5.)\n (\nOPTIONAL\n - if there any floating point issues) Execute:\n\n\nrosrun moveit_kinematics round_collada_numbers.py \nrobotname\n.dae \nrobotname\n_rounded.dae 5\n\n\n\n\n6.)\n Execute\n\n\nopenrave-robot.py \nrobotname\n.dae --info links\n\n\n\n\nThis will list you the links of your robot model. We need the index of the links, that start and end your planning group. Remember them for the next step.\n\n\n7.)\n Edit the command\n\n\npython `openrave-config --python-dir`/openravepy/_openravepy_/ikfast.py --robot=\nrobotname\n.dae --iktype=transform6d --baselink=1 --eelink=8 --savefile=\nikpath\n\n\n\n\n\nso that it fits your robot model.\n\n\n\n\niktype\n is the type of kinematic you can chose. A list with all possible tpyes is \nhere\n\n\nbaselink\n is the index of the starting link for your planning group\n\n\neelink\n is the end effector link of the planning group\n\n\nsavefile\n is the path to your IKFast C++ file. In general chose any path. Go there first and create an empty .cpp file. \nIMPORTANT\n: Give it the name of your planning group \npl\n. Now your \nikpath\n could look like this: \n/home/offi/catkin_ws/src/roboy_ik/src/\npl\n.cpp\n It is important to also include the file into the path.\n\n\n\n\n7.)\n Execute the command from bulletpoint 7.)\n\n\n8.)\n Create the package, where the IKfast solver will be put in.\n\n\ncd ~/catkin_ws/src\ncatkin_create_pkg \nikpkg\n\n\n\n\n\n has to be named like this: \nikfast\n_plugin. Continue with:\n\n\ncd ~/catkin_ws\ncatkin_make\n\n\n\n\n9.)\n Execute\n\n\nrosrun moveit_kinematics create_ikfast_moveit_plugin.py \nrobotname\n \npl\n \nikpkg\n \nikpath\n\n\n\n\n\n10.)\n Add the line \nset(CMAKE_CXX_STANDARD 11)\n to your \nCMakeLists.txt\n of the \nikpkg\n package and finally build your workspace again to create the ik plugin:\n\n\ncd ~/catkin_ws\ncatkin_make\n\n\n\n\nUse IKFast\n\n\nIf everything was successfully built, you can test the plugin. First, ensure that the plugin has been set as the default IK solver for your robot. Do this by running \nrosed \nrobotname\n_moveit_config/config/kinematics.yaml\n or navigate manually to this file.\n\n\nEdit these parts, if not already done:\n\n\nplanning_group_name\n:\n  kinematics_solver: \nrobotname\n_\npl\n_kinematics/IKFastKinematicsPlugin\n-INSTEAD OF-\n  kinematics_solver: kdl_kinematics_plugin/KDLKinematicsPlugin\n\n\n\n\nNow you can test your IK Plugin by running the Demo.launch of your \nrobot_config\n package. Do this by executing \nroslaunch \nrobot_config\n demo_launch\n. Move the endeffector with the markers or sample a random valid position. Check wheather the planning is successful.\n\n\nSources:\n\n\nFacing any issues / compiling errors I can recommend reading the \nofficial MoveIt! IKFast tutorial\n, which includes more detailed information", 
            "title": "IK Solver"
        }, 
        {
            "location": "/issues/#limit-of-kdl-solver", 
            "text": "The ROS MoveIt! KDL solver is only suitable for use with 6 or more DoF kinematic chains. This is an issue that normally would make IK on the PaBiLegs impossible, as this model only has 2 DoF.  To overcome these limitations, MoveIt! allows to use another solver, the so called IKFast solver, which is capable of solving IK equations analytically of any kinematic chain. It even needs less time for the same problem as KDL. IKFast is provided by Rosen Diankov's  OpenRAVE  (Open Robotics Automation Virtual Environment).", 
            "title": "Limit of KDL Solver"
        }, 
        {
            "location": "/issues/#install-ikfast", 
            "text": "", 
            "title": "Install IKFast"
        }, 
        {
            "location": "/issues/#openrave-workstation", 
            "text": "OpenRave for Ubuntu 16.04 Xenial can be downloaded as a robotic workstation by following this  tutorial . Unfortunately many compiling errors occured during all of my attempts. Using the workstation with a graphical visualization by OpenSceneGraph, as it is described in the tutorial, may however not be necessary for this project, as ROS MoveIt! offers an own solution.", 
            "title": "OpenRAVE Workstation"
        }, 
        {
            "location": "/issues/#moveit-ikfast", 
            "text": "MoveIt! IKFast is the name of a MoveIt! tool that helps to generate a IKFast Plugin, that can replace solvers like the KDL solver. There are two ways to install this tool for ROS kinetic.  Binary Install :  sudo apt-get install ros-kinetic-moveit-kinematics  Source  (inside your catkin workspace):  git clone https://github.com/ros-planning/moveit.git", 
            "title": "MoveIt! IKFast"
        }, 
        {
            "location": "/issues/#create-ikfast-plugin", 
            "text": "Is MoveIt! IKFast successfully installed you can start generating your own IKFast solver plugin. In general there are some steps, that have to be done every time you do this for your robot model.\nFirst of all you need to clarify about these descriptions of your robot:   robot name ( robotname ): This is the name of your robot, as it is clarified in your URDF.  planning group name ( pl ): The planning group  IKFast output path ( ikpath ): The path to the C++ file, that will be generated by IKFast and contain the analytical calculations to solve inverse kinematics.  MoveIt! IKFast plugin package ( ikpkg ): The name of your final IKFast Plugin-  MoveIt! robot config ( robot_config ): The name of the config package you created for your robot   IKFast Plugin Creation Step by Step:  1.)  Create a working robot URDF file, as described in the \"Robot Models\" chapter  2.)  Load this URDF in the MoveIt! setup_assisant by running  roslaunch moveit_setup_assistant setup_assistant.launch  3.)  ( OPTIONAL  - if you haven't done it before) Create a new working MoveiIt! Config plugin. Remember the name of planning group and in the last step  \"Configuration files\"  chose the folder of your workspace as output path. Now edit this path by adding  / robotname _moveit_config . This will be the name of your config package. From now on, we will reference  robotname _moveit_config  as  robot_config . Execute  catkin_make  to build the package.  4.)  Navigate into the folder, where the URDF of your robot is saved. Open your terminal here and execute:  rosrun collada_urdf urdf_to_collada  robotname .urdf  robotname .dae  This will generate an .dae file out of the URDF  5.)  ( OPTIONAL  - if there any floating point issues) Execute:  rosrun moveit_kinematics round_collada_numbers.py  robotname .dae  robotname _rounded.dae 5  6.)  Execute  openrave-robot.py  robotname .dae --info links  This will list you the links of your robot model. We need the index of the links, that start and end your planning group. Remember them for the next step.  7.)  Edit the command  python `openrave-config --python-dir`/openravepy/_openravepy_/ikfast.py --robot= robotname .dae --iktype=transform6d --baselink=1 --eelink=8 --savefile= ikpath   so that it fits your robot model.   iktype  is the type of kinematic you can chose. A list with all possible tpyes is  here  baselink  is the index of the starting link for your planning group  eelink  is the end effector link of the planning group  savefile  is the path to your IKFast C++ file. In general chose any path. Go there first and create an empty .cpp file.  IMPORTANT : Give it the name of your planning group  pl . Now your  ikpath  could look like this:  /home/offi/catkin_ws/src/roboy_ik/src/ pl .cpp  It is important to also include the file into the path.   7.)  Execute the command from bulletpoint 7.)  8.)  Create the package, where the IKfast solver will be put in.  cd ~/catkin_ws/src\ncatkin_create_pkg  ikpkg    has to be named like this:  ikfast _plugin. Continue with:  cd ~/catkin_ws\ncatkin_make  9.)  Execute  rosrun moveit_kinematics create_ikfast_moveit_plugin.py  robotname   pl   ikpkg   ikpath   10.)  Add the line  set(CMAKE_CXX_STANDARD 11)  to your  CMakeLists.txt  of the  ikpkg  package and finally build your workspace again to create the ik plugin:  cd ~/catkin_ws\ncatkin_make", 
            "title": "Create IKFast Plugin"
        }, 
        {
            "location": "/issues/#use-ikfast", 
            "text": "If everything was successfully built, you can test the plugin. First, ensure that the plugin has been set as the default IK solver for your robot. Do this by running  rosed  robotname _moveit_config/config/kinematics.yaml  or navigate manually to this file.  Edit these parts, if not already done:  planning_group_name :\n  kinematics_solver:  robotname _ pl _kinematics/IKFastKinematicsPlugin\n-INSTEAD OF-\n  kinematics_solver: kdl_kinematics_plugin/KDLKinematicsPlugin  Now you can test your IK Plugin by running the Demo.launch of your  robot_config  package. Do this by executing  roslaunch  robot_config  demo_launch . Move the endeffector with the markers or sample a random valid position. Check wheather the planning is successful.  Sources:  Facing any issues / compiling errors I can recommend reading the  official MoveIt! IKFast tutorial , which includes more detailed information", 
            "title": "Use IKFast"
        }
    ]
}